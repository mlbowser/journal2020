
## Wednesday, March 25

To do:

* ~~Format and this week's *Refuge Notebook* article to the *Clarion*.~~
* *Refuge Notebook* catch-up.
* Finish blackfish diet analysis.
* Publish blackfish diet raw data.
* Finish metadata for data management team meeting tomorrow.

I edited this week's *Refuge Notebook* article.

I worked on identifications from the blackfish diet analysis, getting the first round of IDs done. BOLD's ID Engine apparently went down, though, so I could not finish re-examining the rotifer sequences.

I attended the biology telecon at 11:00.

I finished editing this week's *Refuge Notebook* article and submitted it to the paper.

I finished scrutinizing identifications and examined the results using R.

```r
setwd("D:/projects/blackfish/2020_blackfish_diet/2020-03_SCVUC/ml-jg")

library(Biostrings)

ids1 <- read.csv("2020-03-25-1313_ids.csv", stringsAsFactors=FALSE)

r3 <- read.csv("results_2020-03-23-1201.csv", stringsAsFactors=FALSE)

dim(ids1)
[1] 212  40
dim(r3)
[1] 275  41

## How many ESVs have we accepted?
sum(ids1$accept==1)
[1] 131

## What is the set of identifications that were accepted?
accid <- levels(as.factor(ids1$scientific_name[ids1$accept==1]))

## How many unique identifications are there?
length(accid)
[1] 103

## I want to see what cutting out all reads except the nominal read length of 313 bp does.
fas1 <- readDNAStringSet("cat.denoised.nonchimeras")
ESV_name <- names(fas1)
fasd <- as.data.frame(ESV_name)
fasd$width <- width(fas1)

ids2 <- merge(ids1, fasd, all.x=TRUE)

## How many unique identifications are accepted and of read length 313?
accid313 <- levels(as.factor(ids2$scientific_name[ids2$accept==1 & ids2$width==313]))
length(accid313)
[1] 79 ## Wow, (103-79)/103 = 23% are dropped. What did we loose?

setdiff(accid, accid313)
 [1] "Aeshna juncea"                             "Aeshna sp. Zotu171"                       
 [3] "Bdelloidea sp. Zotu158"                    "Cyclopidae sp. Zotu83"                    
 [5] "Gyraulus sp. clade B TS-2018 BOLD:AEB5660" "Pleuroxus aduncus"                        
 [7] "Ploima sp. Zotu147"                        "Ploima sp. Zotu151"                       
 [9] "Ploima sp. Zotu153"                        "Ploima sp. Zotu187"                       
[11] "Ploima sp. Zotu188"                        "Procladius sp. BOLD:AAP3007"              
[13] "Rhamphomyia sp. BOLD:ACG3627"              "Rotaria sp. Zotu115"                      
[15] "Rotaria sp. Zotu215"                       "Rotifera sp. Zotu128"                     
[17] "Rotifera sp. Zotu179"                      "Rotifera sp. Zotu30"                      
[19] "Rotifera sp. Zotu40"                       "Rotifera sp. Zotu67"                      
[21] "Rotifera sp. Zotu72"                       "Rotifera sp. Zotu90"                      
[23] "Trichocerca sp. Zotu166"                   "Trichocerca sp. Zotu68"   
## Mostly rotifers are lost here.

## Just having a look at these records.
ids2[ids2$accept==1 & !ids2$width==313,]

## I looked at other files, also. I am going to keep those. I cannot loose that Zotu2, Aeshna juncea, one of the largest Zotus.

## Now I want to prepare a FASTA file to look at the tree.

keeperZotus <- ids1$ESV_name[ids1$accept==1]
keeperlab <- paste0(keeperZotus, " | ", ids1$scientific_name[ids1$accept==1])
keeperlab <- keeperlab[order(keeperlab)]

fask <- fas1[names(fas1) %in% keeperZotus]
fask <- fask[order(names(fask))]

names(fask) <- keeperlab

## Saving.
writeXStringSet(fask, "2020-03-25-1431_accepted_sequences.fas", format="fasta", width=1000)

## Meanwhile, I need to join data together.
r4 <- merge(r3[,1:3], ids2, all.x=TRUE)

## Now I want to remove occurrences with frequencies < 0.05%.

et <- read.delim("ESV.table")
names(et)[1] <- "ESV_name"
et$total <- apply(et[,2:6], 1, sum)
et$min_threshold <- et$total * 0.05/100

et_drop <- et[,1:6]
et_drop[,2:6] <- et[,2:6] <= et$min_threshold
et_drop[,2:6] <- et_drop[,2:6] + 0
et_drop[,2:6] <- et_drop[,2:6] * !et[,2:6]==0

## How many records would be dropped?
sum(et_drop[,2:6])
[1] 2

library(reshape2)
et2 <- melt(et_drop, id.vars="ESV_name")
et2 <- et2[et2$value==1,]
et2
     ESV_name variable value
760     Zotu2    MLB04     1
1015    Zotu4    MLB05     1

r5 <- r4
for (this_record in 1:nrow(et2))
 {
 slesv <- r5$ESV_name == et2$ESV_name[this_record]
 sls <- r5$SampleName == et2$variable[this_record]
 sl <- !(slesv & sls)
 print(sum(sl))
 r5 <- r5[sl,]
 }
 
## Saving here.
write.csv(r5, "results_2020-03-25-1552.csv", row.names=FALSE) 

## How many accepted sample * ESV records do we have?
sum(r5$accept==1)
[1] 167
```
I submitted the FASTA file of accepted sequences to NGPhylogeny.fr using the "NGPhylogeny Analyse - FastME/OneClick" option. Results should be available at <https://ngphylogeny.fr/workspace/history/47db2b18949f0c42>.
